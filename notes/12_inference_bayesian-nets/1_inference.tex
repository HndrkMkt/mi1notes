\section{Inference and Uncertainty}

\mode<presentation>{
\begin{frame} 
    \begin{center} \huge
        \secname
    \end{center}
    \begin{center}
    quanitfying degree of belief/\\
    quanitfying uncertainty
    \end{center}
\end{frame}
}

\subsection{The probabilistic model}

\begin{frame}\frametitle{\subsecname}

\begin{itemize}
    \item \underline{The model:}\\
        \begin{align}
            P(H): H \rightarrow [0,1]&&\\
            P(H) = 0 && \iff H \text{ is false (i.e. impossible)} \\
            P(H) = 1 && \iff H \text{ is true (i.e. certain)} \\
            0 < P(H) < 1 && \text{quantifies our degree of belief}
        \end{align}
    \pause
    \item \textbf{events}: assignment to a set of cases\\
    (e.g. two dice add up to 11)
    \pause
    \item \textbf{proposition}: disjunction of \textbf{events}\\
    (i.e. isolate the sets of \textbf{events} in which the \textbf{proposition} holds)\\
    
\end{itemize}
    
\end{frame}

\begin{frame}

$\underbrace{\text{\emph{Summing over}}}_{\text{marginalisation}}$ the probabilities of the \textbf{events} $\leadsto$ probability of \textbf{proposition}.\\

Example:

\begin{align}
P(\text{Total} = 11) &= P(\text{Die}_{1} = 5, \text{Die}_{2} = 6) + P(\text{Die}_{1} = 6, \text{Die}_{2} = 5)\\
        &\stackrel{\text{shorthand}}{=} P(5,6) + P(6,5)\\
        &= 1 / 36 + 1/36\\
        &= 1/18
\end{align}

$P(\text{Total} = 11), P(5,6) \text{ and } P(6,5)$ are \emph{unconditional} or \emph{prior} probabilities.\\
They represent the degree of belief in the absence of any other information.\\
Priors is also referred to as \emph{domain knowledge}.
        
\end{frame}

\subsection{Evidence}

\begin{frame}\frametitle{\subsecname}

What if we already \emph{know} (i.e. observed) something?\\

e.g. We've already rolled the first die and got 5.\\
Now we're waiting to roll the second die.\\

We are now interested in the \emph{conditional} (or \emph{posterior}) probability of the second die leading to a total of 11:

\begin{equation}
P(\text{Total}= 11) \underbrace{\big|}_{\text{``given''}} \overbrace{\text{Die}_{1}}^{\mathclap{\{1,2,3,4,5,6\}}} = 5)
\end{equation}

\end{frame}

\begin{frame}\frametitle{A thing about priors}

The prior is valid event after the outcome.

e.g.\\
\begin{itemize}
 \item[] $P(\overbrace{cavity}^{\text{Cavity}=1}) = 0.2$
 \item[] $P(cavity | \overbrace{toothache}^{\text{Toothache}=1}) = 0.6$
 \item[] If we observe that a cavity has actually occured, we don't have to change our prior on cavities.\\
 However, the prior becomes less useful if we proceed to infer other things.
\end{itemize}
    
\textbf{Caution}\\
\begin{itemize}
\item[$\times$] Whenever Toothache is true, then cavity is true with probability of 0.6
\item[\checkmark] Whenever Toothache is true, \textit{and no other information} is available, then cavity is true with probability of 0.6.
\end{itemize}

\textit{other information}: Diagnosis was \underline{no} cavity. In this case, the probability is no longer 0.6, but:
\begin{equation}
P(cavity | toothache \wedge Diagnosis cavity = false) = 0
\end{equation}

\end{frame}

Observing event e rules out events where e is false. This leaves a set where $P(e)>0$.
We look within that set for the fraction that satisfies $x$ and $e$.

This fraction is


\begin{frame}
    
\end{frame}
