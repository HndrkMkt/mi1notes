\section{Precursor: Method of Lagrange Multipliers}


\begin{frame}\frametitle{\secname} 
    \begin{center}
    \slidesonly{\huge}
	Don't panic!
    \end{center}
    \begin{center}
        Essentially just hill-climbing (gradient ascent)
    \end{center}
    \pause

\underline{Objective}: \\
\textit{Maximize} an objective function while also satisfying some constraint(s).\\
{
\small(\textit{Maximize}: Find the arguments that maximize an objective function.)
}\\[5mm]
Don't forget: any maximization problem can be turned into a minimization problem\notesonly{ by maximizing the ``negative'' of the function}.
\end{frame}

\subsection{Gradient ascent - unconstrained optimization}
\begin{frame}\frametitle{\subsecname}
Maximize an objective function $f(w_1, w_2)$ (no constraints here).\\
Here $w_1$ and $w_2$ are referred to as free parameters.\\

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{img/lagrange_objfunction.pdf}
	\mode<article>{
	\caption{
	The objective function $f$ we want to maximize (i.e. reach the blue ${\color{blue}\times}$ at the top). $c_1$ and $c_2$ are level curves where $f$ is constant. 
	The blue arrows indicate the direction of the gradient $\vec \nabla f$, which is always perpendicular to the level curve.
	}
	}
\end{figure}
\slidesonly{
\vspace{-3mm}
}
The gradient $\vec \nabla f$ describes the direction of greatest ascent:\\
\slidesonly{
\vspace{-3mm}
}
\begin{equation}
\vec \nabla f = 
\frac{\partial f}{\partial \vec w} = 
\rmat{\frac{\partial f}{\partial w_1} \\[0.2cm] \frac{\partial f}{\partial w_1} }
\end{equation}

\end{frame}


\newpage

\subsection{Adding a single constraint}
\begin{frame}\frametitle{\subsecname}
We restrict solutions to those that satisfy the constraint $g(w_1, w_2) = c$:

\begin{figure}[h]
\centering
\includegraphics[width=0.7\linewidth]{img/lagrange_objfunction_constrained}
\mode<article>{
\caption{The surface of the constaint cuts through the surface of the objective function. The highest point that can be reached on $f$ which also intersects with $g$ is unique in that the gradients of $f$ and $g$ both point in the same direction with only a difference in scale.}
}
\end{figure}

\only<1,2>{
\question{What is characteristic of the solution to the constrained optimization problem?}\\
}
\notesonly{
-The solution of the constrained optimization problem is characterized by:
}
\only<2>{
\slidesonly{\vspace{-5mm}}
\begin{equation}
    \vec \nabla f = \lambda' \vec \nabla g\,,\quad
\text{where $\lambda'$ is a scaling factor.}
\label{eq:equality}
\end{equation}
}
\notesonly{\eqref{eq:equality} holds for the highest position in $f$ while also satisfying the constraint.\\

Consequently,}
% temporarily change footnote marks to symbols so not to confuse with exponents
\renewcommand*{\thefootnote}{\fnsymbol{footnote}}
\only<3>{
\slidesonly{\vspace{-5mm}}
\begin{align}
  \vec \nabla f \; - \lambda' \vec \nabla g     &= \vec 0 \\
  \vec \nabla f \; + \underbrace{(- \lambda')}_{=:\lambda} \vec \nabla g &= \vec 0 \\
  \vec \nabla f \;  + \lambda \vec \nabla g      &= \vec 0\notesonly{\;\footnotemark }
  \label{eq:equalitylambda}
\end{align}
}
\notesonly{
    \footnotetext{
    The switch from $\lambda'$ to $\lambda$ is to be more consistent with lecture slides.
    }
}
% change footnote marks back to original scheme (numbers)
\renewcommand*{\thefootnote}{\arabic{footnote}}

\end{frame}

\begin{frame}
%\newpage
The constrained optimization problem is formulated as:

\begin{equation}
\underbrace{f(w_1, w_2) \;\eqexcl\; \max_{w_{1},w_{2}}}_{\text{maximization}} \quad  \text{subject to} \quad \underbrace{g(w_1,w_2)\;-c\; = \; 0}_{\text{a single constraint}}
\label{eq:optconstrained}
\end{equation}

\notesonly{
The \emph{Lagrangian} function reformulates the constrained optimization problem from \eqref{eq:optconstrained} in a way that reflects the relationship of the two gradients at the solution and thus facilitate finding the solution \eqref{eq:equalitylambda}.} The Lagrangian is therefore defined as:

\begin{equation}
L(w_1, w_2, \lambda) \; = \; f(w_1,w_2) + \lambda(g(w_1, w_2)-c)
\end{equation}

Setting the gradient $\nabla L$ to zero guarantees $\vec \nabla f \;  + \lambda \vec \nabla g = \vec 0$

\pause 

\begin{equation}
\vec \nabla L = 
\rmat{
	\frac{\partial L}{\partial w_1} \\[0.5cm]
	\frac{\partial L}{\partial w_2} \\[0.5cm]
	\frac{\partial L}{\partial \lambda}
	}
=
\rmat{
	\frac{\partial f}{\partial w_1} \quad+\quad \lambda \frac{\partial g}{\partial w_1} \\[0.3cm]
	\frac{\partial f}{\partial w_2} \quad+\quad \lambda \frac{\partial g}{\partial w_2} \\[0.3cm]
	\underbrace{\frac{\partial f}{\partial \lambda}}_{=0} \;+\; g(w_1, w_2)-c
	}
=
\rmat{
	0 \\[0.5cm]
	0 \\[0.5cm]
    0
	}
= \vec 0
\label{eq:lagrangiangrad}
\end{equation}

Setting the first two elements of $\nabla L$\notesonly{, namely $\frac{\partial L}{\partial w_1}$ and $\frac{\partial L}{\partial w_2}$,} to zero ensures that $\nabla f = -\lambda \nabla g$,\\
while $\frac{\partial L}{\partial \lambda}=0$ ensures that $g(w_1, w_2) = c$.\\

\eqref{eq:lagrangiangrad} describes a system of 3 equations with 3 unknowns.\\

We refer to $\lambda$ as the \emph{multiplier} for constraint $c$.

\end{frame}

\begin{frame}\frametitle{Example}
 
    
\end{frame}

\subsection{Multiple constraints}

\begin{frame}
 
\question{How do we extend this to multiple constraints?}
    
$$
\underbrace{f_0(\vec w) \;\eqexcl\; \text{max}}_{\text{maximization}} \quad  \text{and} \quad f_k(\vec w)\;\le\; = \; 0 \;, \quad k = 1,\ldots,m
$$

where $m$ denotes the number of constraints.

The Lagrangian is then defined as:

$$
L(\,\vec w\;, \underbrace{\{\lambda_k\}}_{
\mathclap{
\substack{\text{a multiplier} \\
\text{for each constraint}}
}
}) \; = \; f_0(\vec w) + \sum_{k=1}^{m} \lambda_k \, f_k(\vec w)
$$


\end{frame}

